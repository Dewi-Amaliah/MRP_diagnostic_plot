@inbook{cochrane,
author = {Green, Sally and Higgins, Julian PT and Alderson, Philip and Clarke, Mike and Mulrow, Cynthia D and Oxman, Andrew D},
publisher = {John Wiley \& Sons, Ltd},
isbn = {9780470712184},
title = {Introduction},
booktitle = {Cochrane Handbook for Systematic Reviews of Interventions},
chapter = {1},
pages = {1-9},
doi = {https://doi.org/10.1002/9780470712184.ch1},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9780470712184.ch1},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9780470712184.ch1},
year = {2008},
keywords = {Cochrane Collaboration and healthcare, Cochrane Collaboration principles, Cochrane Collaboration and Cochrane Review Groups (CRGs), Cochrane Methods Groups, Cochrane Database of Systematic Reviews (CDSR), Cochrane reviews - systematic review, Cochrane Handbook for Systematic Reviews of Interventions (Version 5), ‘The Cochrane Collaboration Tool Kit’},
abstract = {Summary This chapter contains sections titled: The Cochrane Collaboration Systematic reviews About this Handbook Contributors to the Handbook Chapter information References}
}

@misc{brown_uni, 
    title={Scientific Literature Review Resources and Services}, 
    url={https://libguides.brown.edu/Reviews/types}, 
    author={{Brown University Library}}, 
    year={2021}, 
}

@article{SchweizerMarinL2017Apgt,
issn = {0196-6553},
abstract = {Systematic literature reviews and meta-analyses are important research designs used to summarize and derive conclusions about the collective evidence on a focused research question in a structured, reproducible manner. The goal of this Methodology Minute is to describe how to conduct a systematic literature review and meta-analysis using a step-by-step approach to help infection preventionists (IPs) and others in the field perform their own systematic literature review and meta-analysis, and to critically evaluate published systematic literature reviews and meta-analyses.},
journal = {American journal of infection control},
pages = {1292--1294},
volume = {45},
publisher = {Elsevier Inc},
number = {11},
year = {2017},
title = {A practical guide to systematic literature reviews and meta-analyses in infection prevention: Planning, challenges, and execution},
copyright = {2017},
language = {eng},
address = {United States},
author = {Schweizer, Marin L and Nair, Rajeshwari},
keywords = {Meta-Analysis as Topic ; Infection Control - methods ; Review Literature as Topic ; Humans ; Career development ; Medical colleges ; Health aspects},
}

@Book{ggplot2,
    author = {Hadley Wickham},
    title = {ggplot2: Elegant Graphics for Data Analysis},
    publisher = {Springer-Verlag New York},
    year = {2016},
    isbn = {978-3-319-24277-4},
    url = {https://ggplot2.tidyverse.org},
  }
  
  
@Manual{prisma2020,
    title = {PRISMA2020: R package and ShinyApp for producing PRISMA 2020 compliant flow diagrams (Version 0.0.2)},
    author = {Neal R Haddaway and Chris C Pritchard and Luke A McGuinness},
    year = {2021},
    doi = {10.5281/zenodo.5082518},
  }
  
@article{LinnenlueckeMartinaK2020Cslr,
issn = {0312-8962},
abstract = {Literature reviews play an essential role in academic research to gather existing knowledge and to examine the state of a field. However, researchers in business, management and related disciplines continue to rely on cursory and narrative reviews that lack a systematic investigation of the literature. This article details methodological steps for conducting literature reviews in a replicable and scientific fashion. This article also discusses bibliographic mapping approaches to visualise bibliometric information and findings from a systematic literature review. We hope that the insights provided in this article are useful for researchers at different stages of their careers - ranging from doctoral students who wish to assemble a broad overview of their field of interest to guide their work, to senior researchers who wish to publish authoritative literature reviews.},
journal = {Australian journal of management},
pages = {175--194},
volume = {45},
publisher = {SAGE Publications},
number = {2},
year = {2020},
title = {Conducting systematic literature reviews and bibliometric analyses},
copyright = {The Author(s) 2019},
language = {eng},
address = {London, England},
author = {Linnenluecke, Martina K and Marrone, Mauricio and Singh, Abhay K},
keywords = {Bibliometrics ; Business ; Business & Economics ; Entity (Philosophy) ; Evaluation ; Literature reviews ; MANAGEMENT ; RESEARCH ; Researchers ; Reviews ; Social Sciences ; Text data mining},
}

@Article{layered-grammar,
  author = {Hadley Wickham},
  doi = {10.1198/jcgs.2009.07098},
  journal = {Journal of Computational and Graphical Statistics},
  number = {1},
  pages = {3–28},
  selected = {TRUE},
  title = {A layered grammar of graphics},
  volume = {19},
  year = {2010},
  bdsk-url-1 = {http://dx.doi.org/10.1198/jcgs.2009.07098},
}


@Article{vanderplas,
  author = {Vanderplas, Susan and Cook, Dianne and Hofmann, Heike},
  doi = {10.1146/annurev-statistics-031219-041252},
  journal = {Annual Review of Statistics and Its Application},
  number = {1},
  pages = {61–88},
  selected = {TRUE},
  title = {Testing Statistical Charts: What Makes a Good Graph?},
  volume = {7},
  year = {2020},
  bdsk-url-1 = {http://dx.doi.org/10.1146/annurev-statistics-031219-041252},
}


@article{MIDWAY2020100141,
title = {Principles of Effective Data Visualization},
journal = {Patterns},
volume = {1},
number = {9},
pages = {100141},
year = {2020},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2020.100141},
url = {https://www.sciencedirect.com/science/article/pii/S2666389920301896},
author = {Stephen R. Midway},
abstract = {Summary
We live in a contemporary society surrounded by visuals, which, along with software options and electronic distribution, has created an increased importance on effective scientific visuals. Unfortunately, across scientific disciplines, many figures incorrectly present information or, when not incorrect, still use suboptimal data visualization practices. Presented here are ten principles that serve as guidance for authors who seek to improve their visual message. Some principles are less technical, such as determining the message before starting the visual, while other principles are more technical, such as how different color combinations imply different information. Because figure making is often not formally taught and figure standards are not readily enforced in science, it is incumbent upon scientists to be aware of best practices in order to most effectively tell the story of their data.}
}

@article{BotchkarevAlexei2019ANTD,
issn = {1555-1229},
abstract = {Aim/Purpose: The aim of this study was to analyze various performance metrics and approaches to their classification. The main goal of the study was to develop a new typology that will help to advance knowledge of metrics and facilitate their use in machine learning regression algorithms Background: Performance metrics (error measures) are vital components of the evaluation frameworks in various fields. A performance metric can be defined as a logical and mathematical construct designed to measure how close are the actual results from what has been expected or predicted. A vast variety of performance metrics have been described in academic literature. The most commonly mentioned metrics in research studies are Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), etc. Knowledge about metrics properties needs to be systematized to simplify the design and use of the metrics. Methodology: A qualitative study was conducted to achieve the objectives of identifying related peer-reviewed research studies, literature reviews, critical thinking and inductive reasoning. Contribution: The main contribution of this paper is in ordering knowledge of performance metrics and enhancing understanding of their structure and properties by proposing a new typology, generic primary metrics mathematical formula and a visualization chart Findings: Based on the analysis of the structure of numerous performance metrics, we proposed a framework of metrics which includes four (4) categories: primary metrics, extended metrics, composite metrics, and hybrid sets of metrics. The paper identified three (3) key components (dimensions) that determine the structure and properties of primary metrics: method of determining point distance, method of normalization, method of aggregation of point distances over a data set. For each component, implementation options have been identified. The suggested new typology has been shown to cover a total of over 40 commonly used primary metrics Recommendations for Practitioners: Presented findings can be used to facilitate teaching performance metrics to university students and expedite metrics selection and implementation processes for practitioners Recommendation for Researchers: By using the proposed typology, researchers can streamline development of new metrics with predetermined properties Impact on Society: The outcomes of this study could be used for improving evaluation results in machine learning regression, forecasting and prognostics with direct or indirect positive impacts on innovation and productivity in a societal sense Future Research: Future research is needed to examine the properties of the extended metrics, composite metrics, and hybrid sets of metrics. Empirical study of the metrics is needed using R Studio or Azure Machine Learning Studio, to find associations between the properties of primary metrics and their “numerical” behavior in a wide spectrum of data characteristics and business or research requirements},
journal = {Interdisciplinary journal of information, knowledge, and management},
pages = {45--76},
volume = {14},
year = {2019},
title = {A New Typology Design of Performance Metrics to Measure Errors in Machine Learning Regression Algorithms},
language = {eng},
author = {Botchkarev, Alexei},
}


@article{ChaiT2014Rmse,
issn = {1991-9603},
abstract = {Both the root mean square error (RMSE) and the mean absolute error (MAE) are regularly employed in model evaluation studies. Willmott and Matsuura (2005) have suggested that the RMSE is not a good indicator of average model performance and might be a misleading indicator of average error, and thus the MAE would be a better metric for that purpose. While some concerns over using RMSE raised by Willmott and Matsuura (2005) and Willmott et al. (2009) are valid, the proposed avoidance of RMSE in favor of MAE is not the solution. Citing the aforementioned papers, many researchers chose MAE over RMSE to present their model evaluation statistics when presenting or adding the RMSE measures could be more beneficial. In this technical note, we demonstrate that the RMSE is not ambiguous in its meaning, contrary to what was claimed by Willmott et al. (2009). The RMSE is more appropriate to represent model performance than the MAE when the error distribution is expected to be Gaussian. In addition, we show that the RMSE satisfies the triangle inequality requirement for a distance metric, whereas Willmott et al. (2009) indicated that the sums-of-squares-based statistics do not satisfy this rule. In the end, we discussed some circumstances where using the RMSE will be more beneficial. However, we do not contend that the RMSE is superior over the MAE. Instead, a combination of metrics, including but certainly not limited to RMSEs and MAEs, are often required to assess model performance.},
journal = {Geoscientific model development},
pages = {1247--1250},
volume = {7},
publisher = {Copernicus GmbH},
number = {3},
year = {2014},
title = {Root mean square error (RMSE) or mean absolute error (MAE)? – Arguments against avoiding RMSE in the literature},
copyright = {COPYRIGHT 2014 Copernicus GmbH},
language = {eng},
author = {Chai, T and Draxler, R. R},
}


@article{WillmottCJ2005Aotm,
issn = {0936-577X},
abstract = {The relative abilities of 2, dimensioned statistics—the root-mean-square error (RMSE) and the mean absolute error (MAE)—to describe average model-performance error are examined. The RMSE is of special interest because it is widely reported in the climatic and environmental literature; nevertheless, it is an inappropriate and misinterpreted measure of average error. RMSE is inappropriate because it is a function of 3 characteristics of a set of errors, rather than of one (the average error). RMSE varies with the variability within the distribution of error magnitudes and with the square root of the number of errors (
), as well as with the average-error magnitude (MAE). Our findings indicate that MAE is a more natural measure of average error, and (unlike RMSE) is unambiguous. Dimensioned evaluations and inter-comparisons of average model-performance error, therefore, should be based on MAE.},
journal = {Climate research},
pages = {79--82},
volume = {30},
publisher = {Inter-Research},
number = {1},
year = {2005},
title = {Advantages of the mean absolute error (MAE) over the root mean square error (RMSE) in assessing average model performance},
copyright = {Inter-Research 2005},
language = {eng},
author = {Willmott, CJ and Matsuura, K},
keywords = {Arithmetic mean ; Error rates ; Errors in statistics ; Estimate reliability ; Geography ; Modeling ; NOTE ; Precipitation ; Root mean square errors ; Statistical variance},
}