@inbook{cochrane,
author = {Green, Sally and Higgins, Julian PT and Alderson, Philip and Clarke, Mike and Mulrow, Cynthia D and Oxman, Andrew D},
publisher = {John Wiley \& Sons, Ltd},
isbn = {9780470712184},
title = {Introduction},
booktitle = {Cochrane Handbook for Systematic Reviews of Interventions},
chapter = {1},
pages = {1-9},
doi = {https://doi.org/10.1002/9780470712184.ch1},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9780470712184.ch1},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9780470712184.ch1},
year = {2008},
keywords = {Cochrane Collaboration and healthcare, Cochrane Collaboration principles, Cochrane Collaboration and Cochrane Review Groups (CRGs), Cochrane Methods Groups, Cochrane Database of Systematic Reviews (CDSR), Cochrane reviews - systematic review, Cochrane Handbook for Systematic Reviews of Interventions (Version 5), ‘The Cochrane Collaboration Tool Kit’},
abstract = {Summary This chapter contains sections titled: The Cochrane Collaboration Systematic reviews About this Handbook Contributors to the Handbook Chapter information References}
}

@misc{brown_uni, 
    title={Scientific Literature Review Resources and Services}, 
    url={https://libguides.brown.edu/Reviews/types}, 
    author={{Brown University Library}}, 
    year={2021}, 
}

@article{SchweizerMarinL2017Apgt,
issn = {0196-6553},
abstract = {Systematic literature reviews and meta-analyses are important research designs used to summarize and derive conclusions about the collective evidence on a focused research question in a structured, reproducible manner. The goal of this Methodology Minute is to describe how to conduct a systematic literature review and meta-analysis using a step-by-step approach to help infection preventionists (IPs) and others in the field perform their own systematic literature review and meta-analysis, and to critically evaluate published systematic literature reviews and meta-analyses.},
journal = {American journal of infection control},
pages = {1292--1294},
volume = {45},
publisher = {Elsevier Inc},
number = {11},
year = {2017},
title = {A practical guide to systematic literature reviews and meta-analyses in infection prevention: Planning, challenges, and execution},
copyright = {2017},
language = {eng},
address = {United States},
author = {Schweizer, Marin L and Nair, Rajeshwari},
keywords = {Meta-Analysis as Topic ; Infection Control - methods ; Review Literature as Topic ; Humans ; Career development ; Medical colleges ; Health aspects},
}

@Book{ggplot2,
    author = {Hadley Wickham},
    title = {ggplot2: Elegant Graphics for Data Analysis},
    publisher = {Springer-Verlag New York},
    year = {2016},
    isbn = {978-3-319-24277-4},
    url = {https://ggplot2.tidyverse.org},
  }
  
  
@Manual{prisma2020,
    title = {PRISMA2020: R package and ShinyApp for producing PRISMA 2020 compliant flow diagrams (Version 0.0.2)},
    author = {Neal R Haddaway and Chris C Pritchard and Luke A McGuinness},
    year = {2021},
    doi = {10.5281/zenodo.5082518},
  }
  
@article{LinnenlueckeMartinaK2020Cslr,
issn = {0312-8962},
abstract = {Literature reviews play an essential role in academic research to gather existing knowledge and to examine the state of a field. However, researchers in business, management and related disciplines continue to rely on cursory and narrative reviews that lack a systematic investigation of the literature. This article details methodological steps for conducting literature reviews in a replicable and scientific fashion. This article also discusses bibliographic mapping approaches to visualise bibliometric information and findings from a systematic literature review. We hope that the insights provided in this article are useful for researchers at different stages of their careers - ranging from doctoral students who wish to assemble a broad overview of their field of interest to guide their work, to senior researchers who wish to publish authoritative literature reviews.},
journal = {Australian journal of management},
pages = {175--194},
volume = {45},
publisher = {SAGE Publications},
number = {2},
year = {2020},
title = {Conducting systematic literature reviews and bibliometric analyses},
copyright = {The Author(s) 2019},
language = {eng},
address = {London, England},
author = {Linnenluecke, Martina K and Marrone, Mauricio and Singh, Abhay K},
keywords = {Bibliometrics ; Business ; Business & Economics ; Entity (Philosophy) ; Evaluation ; Literature reviews ; MANAGEMENT ; RESEARCH ; Researchers ; Reviews ; Social Sciences ; Text data mining},
}

@Article{layered-grammar,
  author = {Hadley Wickham},
  doi = {10.1198/jcgs.2009.07098},
  journal = {Journal of Computational and Graphical Statistics},
  number = {1},
  pages = {3–28},
  selected = {TRUE},
  title = {A layered grammar of graphics},
  volume = {19},
  year = {2010},
  bdsk-url-1 = {http://dx.doi.org/10.1198/jcgs.2009.07098},
}


@Article{vanderplas,
  author = {Vanderplas, Susan and Cook, Dianne and Hofmann, Heike},
  doi = {10.1146/annurev-statistics-031219-041252},
  journal = {Annual Review of Statistics and Its Application},
  number = {1},
  pages = {61–88},
  selected = {TRUE},
  title = {Testing Statistical Charts: What Makes a Good Graph?},
  volume = {7},
  year = {2020},
  bdsk-url-1 = {http://dx.doi.org/10.1146/annurev-statistics-031219-041252},
}


@article{MIDWAY2020100141,
title = {Principles of Effective Data Visualization},
journal = {Patterns},
volume = {1},
number = {9},
pages = {100141},
year = {2020},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2020.100141},
url = {https://www.sciencedirect.com/science/article/pii/S2666389920301896},
author = {Stephen R. Midway},
abstract = {Summary
We live in a contemporary society surrounded by visuals, which, along with software options and electronic distribution, has created an increased importance on effective scientific visuals. Unfortunately, across scientific disciplines, many figures incorrectly present information or, when not incorrect, still use suboptimal data visualization practices. Presented here are ten principles that serve as guidance for authors who seek to improve their visual message. Some principles are less technical, such as determining the message before starting the visual, while other principles are more technical, such as how different color combinations imply different information. Because figure making is often not formally taught and figure standards are not readily enforced in science, it is incumbent upon scientists to be aware of best practices in order to most effectively tell the story of their data.}
}

@article{BotchkarevAlexei2019ANTD,
issn = {1555-1229},
abstract = {Aim/Purpose: The aim of this study was to analyze various performance metrics and approaches to their classification. The main goal of the study was to develop a new typology that will help to advance knowledge of metrics and facilitate their use in machine learning regression algorithms Background: Performance metrics (error measures) are vital components of the evaluation frameworks in various fields. A performance metric can be defined as a logical and mathematical construct designed to measure how close are the actual results from what has been expected or predicted. A vast variety of performance metrics have been described in academic literature. The most commonly mentioned metrics in research studies are Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), etc. Knowledge about metrics properties needs to be systematized to simplify the design and use of the metrics. Methodology: A qualitative study was conducted to achieve the objectives of identifying related peer-reviewed research studies, literature reviews, critical thinking and inductive reasoning. Contribution: The main contribution of this paper is in ordering knowledge of performance metrics and enhancing understanding of their structure and properties by proposing a new typology, generic primary metrics mathematical formula and a visualization chart Findings: Based on the analysis of the structure of numerous performance metrics, we proposed a framework of metrics which includes four (4) categories: primary metrics, extended metrics, composite metrics, and hybrid sets of metrics. The paper identified three (3) key components (dimensions) that determine the structure and properties of primary metrics: method of determining point distance, method of normalization, method of aggregation of point distances over a data set. For each component, implementation options have been identified. The suggested new typology has been shown to cover a total of over 40 commonly used primary metrics Recommendations for Practitioners: Presented findings can be used to facilitate teaching performance metrics to university students and expedite metrics selection and implementation processes for practitioners Recommendation for Researchers: By using the proposed typology, researchers can streamline development of new metrics with predetermined properties Impact on Society: The outcomes of this study could be used for improving evaluation results in machine learning regression, forecasting and prognostics with direct or indirect positive impacts on innovation and productivity in a societal sense Future Research: Future research is needed to examine the properties of the extended metrics, composite metrics, and hybrid sets of metrics. Empirical study of the metrics is needed using R Studio or Azure Machine Learning Studio, to find associations between the properties of primary metrics and their “numerical” behavior in a wide spectrum of data characteristics and business or research requirements},
journal = {Interdisciplinary journal of information, knowledge, and management},
pages = {45--76},
volume = {14},
year = {2019},
title = {A New Typology Design of Performance Metrics to Measure Errors in Machine Learning Regression Algorithms},
language = {eng},
author = {Botchkarev, Alexei},
}


@article{ChaiT2014Rmse,
issn = {1991-9603},
abstract = {Both the root mean square error (RMSE) and the mean absolute error (MAE) are regularly employed in model evaluation studies. Willmott and Matsuura (2005) have suggested that the RMSE is not a good indicator of average model performance and might be a misleading indicator of average error, and thus the MAE would be a better metric for that purpose. While some concerns over using RMSE raised by Willmott and Matsuura (2005) and Willmott et al. (2009) are valid, the proposed avoidance of RMSE in favor of MAE is not the solution. Citing the aforementioned papers, many researchers chose MAE over RMSE to present their model evaluation statistics when presenting or adding the RMSE measures could be more beneficial. In this technical note, we demonstrate that the RMSE is not ambiguous in its meaning, contrary to what was claimed by Willmott et al. (2009). The RMSE is more appropriate to represent model performance than the MAE when the error distribution is expected to be Gaussian. In addition, we show that the RMSE satisfies the triangle inequality requirement for a distance metric, whereas Willmott et al. (2009) indicated that the sums-of-squares-based statistics do not satisfy this rule. In the end, we discussed some circumstances where using the RMSE will be more beneficial. However, we do not contend that the RMSE is superior over the MAE. Instead, a combination of metrics, including but certainly not limited to RMSEs and MAEs, are often required to assess model performance.},
journal = {Geoscientific model development},
pages = {1247--1250},
volume = {7},
publisher = {Copernicus GmbH},
number = {3},
year = {2014},
title = {Root mean square error (RMSE) or mean absolute error (MAE)? – Arguments against avoiding RMSE in the literature},
copyright = {COPYRIGHT 2014 Copernicus GmbH},
language = {eng},
author = {Chai, T and Draxler, R. R},
}


@article{WillmottCJ2005Aotm,
issn = {0936-577X},
abstract = {The relative abilities of 2, dimensioned statistics—the root-mean-square error (RMSE) and the mean absolute error (MAE)—to describe average model-performance error are examined. The RMSE is of special interest because it is widely reported in the climatic and environmental literature; nevertheless, it is an inappropriate and misinterpreted measure of average error. RMSE is inappropriate because it is a function of 3 characteristics of a set of errors, rather than of one (the average error). RMSE varies with the variability within the distribution of error magnitudes and with the square root of the number of errors (
), as well as with the average-error magnitude (MAE). Our findings indicate that MAE is a more natural measure of average error, and (unlike RMSE) is unambiguous. Dimensioned evaluations and inter-comparisons of average model-performance error, therefore, should be based on MAE.},
journal = {Climate research},
pages = {79--82},
volume = {30},
publisher = {Inter-Research},
number = {1},
year = {2005},
title = {Advantages of the mean absolute error (MAE) over the root mean square error (RMSE) in assessing average model performance},
copyright = {Inter-Research 2005},
language = {eng},
author = {Willmott, CJ and Matsuura, K},
keywords = {Arithmetic mean ; Error rates ; Errors in statistics ; Estimate reliability ; Geography ; Modeling ; NOTE ; Precipitation ; Root mean square errors ; Statistical variance},
}

@misc{few_2008, 
title={Practical rules for using color in charts - GitHub Pages}, 
url={https://nbisweden.github.io/Rcourse/files/rules_for_using_color.pdf}, 
author={Few, Stephen}, 
year={2008}, 
month={Feb}} 

@misc{Gelman97poststratificationinto,
author = {Andrew Gelman and Thomas C. Little},
title = {Poststratification Into Many Categories Using Hierarchical Logistic Regression},
year = {1997}
}

@article{BISBEEJAMES2019BIMP,
issn = {0003-0554},
abstract = {Multilevel regression and post-stratification (MRP) is the current gold standard for extrapolating opinion data from nationally representative surveys to smaller geographic units. However, innovations in nonparametric regularization methods can further improve the researcher’s ability to extrapolate opinion data to a geographic unit of interest. I test an ensemble of regularization algorithms and find that there is room for substantial improvement on the multilevel model via more flexible methods of regularization. I propose a modified version of MRP that replaces the multilevel model with a nonparametric approach called Bayesian additive regression trees (BART or, when combined with post-stratification, BARP). I compare both methods across a number of data contexts, demonstrating the benefits of applying more powerful regularization methods to extrapolate opinion data to target geographical units. I provide an R package that implements the BARP method.},
journal = {The American political science review},
pages = {1060--1065},
volume = {113},
publisher = {Cambridge University Press},
number = {4},
year = {2019},
title = {BARP: Improving Mister P Using Bayesian Additive Regression Trees},
copyright = {Copyright © American Political Science Association 2019},
language = {eng},
address = {New York, USA},
author = {Bisbee, James},
keywords = {Additives ; Bayesian analysis ; Innovations ; Stratification ; Trees},
}

@article{GelmanAndrew2014HBAC,
issn = {0883-4237},
abstract = {In the United States as in other countries, political and economic divisions cut along geographic and demographic lines. Richer people are more likely to vote for Republican candidates while poorer voters lean Democratic; this is consistent with the positions of the two parties on economic issues. At the same time, richer states on the coasts are bastions of the Democrats, while most of the generally lower-income areas in the middle of the country strongly support Republicans. During a research project lasting several years, we reconciled these patterns by fitting a series of multilevel models to perform inference on geographic and demographic subsets of the population. We were using national survey data with relatively small samples in some states, ethnic groups and income categories; this motivated the use of Bayesian inference to partially pool between fitted models and local data. Previous, non-Bayesian analyses of income and voting had failed to connect individual and state-level patterns. Now that our analysis has been done, we believe it could be replicated using non-Bayesian methods, but Bayesian inference helped us crack the problem by directly handling the uncertainty that is inherent in working with sparse data.},
journal = {Statistical science},
pages = {26--35},
volume = {29},
publisher = {Institute of Mathematical Statistics},
number = {1},
year = {2014},
title = {How Bayesian Analysis Cracked the Red-State, Blue-State Problem},
copyright = {Copyright © 2014 Institute of Mathematical Statistics},
language = {eng},
address = {Hayward},
author = {Gelman, Andrew},
keywords = {Bayesian analysis ; Big Bayes Stories: A Collection of Vignettes ; Candidates ; Ethnicity ; Income estimates ; Inference ; Liberalism ; Modeling ; Multilevel models ; Multilevel regression and poststratification (MRP) ; Political parties ; political science ; sample surveys ; sparse data ; States ; Statistical inference ; Survey sampling ; Voter behavior ; Voting ; Voting patterns},
}

@article{GhitzaYair2013DIwM,
issn = {0092-5853},
journal = {American journal of political science},
pages = {762--776},
volume = {57},
number = {3},
year = {2013},
title = {Deep Interactions with MRP: Election Turnout and Voting Patterns Among Small Electoral Subgroups: DEEP INTERACTIONS WITH MRP},
language = {eng},
author = {Ghitza, Yair and Gelman, Andrew},
}

@article{KiewietdeJongeChadP2018PSPE,
issn = {0033-362X},
abstract = {Abstract
This paper presents state-level estimates of the 2016 presidential election using data from the ABC News/Washington Post tracking poll and multilevel regression with poststratification (MRP). While previous implementations of MRP for election forecasting have relied on data from prior elections to establish poststratification targets for the composition of the electorate, in this paper we estimate both turnout and vote preference from the same preelection poll. Through Bayesian estimation we are also able to capture uncertainty in both estimated turnout and vote preferences. This approach correctly predicts 50 of 51 contests, showing greater accuracy than comparison models that rely on the 2012 Current Population Survey Voting and Registration Supplement for turnout. While the model does not perfectly estimate turnout as a share of the voting age population, popular vote shares, or vote margins in each state, it is more accurate than predictions published by polling aggregators or other published MRP estimators. The paper also reports how vote preferences changed over the course of the 18-day tracking period, compares subgroup-level estimates of turnout and vote preferences with the 2016 CPS Survey and National Election Pool exit poll, and summarizes the accuracy of the approach applied to the 2000, 2004, 2008, and 2012 elections. The paper concludes by discussing how researchers can make use of this method as an alternative approach to survey weighting and likely voter modeling as well as in forecasting future elections.},
journal = {Public opinion quarterly},
pages = {419--446},
volume = {82},
publisher = {Oxford University Press},
number = {3},
year = {2018},
title = {Predicting State Presidential Election Results Using National Tracking Polls and Multilevel Regression with Poststratification (MRP)},
copyright = {The Author(s) 2018. Published by Oxford University Press on behalf of the American Association for Public Opinion Research. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com 2018},
language = {eng},
address = {US},
author = {Kiewiet de Jonge, Chad P and Langer, Gary and Sinozich, Sofi},
}

@article{LauderdaleBenjaminE2020Mppf,
issn = {0169-2070},
abstract = {We describe a strategy for applying multilevel regression and post-stratification (MRP) methods to pre-election polling. Using a combination of contemporaneous polling, census data, past election polling, past election results, and other sources of information, we are able to construct probabilistic, internally consistent estimates of national votes and the sub-national electoral districts that determine seats or electoral votes in many electoral systems. We report on the performance of the general framework in three applications that were conducted and released publicly in advance of the 2016 UK Referendum on EU Membership, the 2016 US Presidential Election, and the 2017 UK General Election.},
journal = {International journal of forecasting},
pages = {399--413},
volume = {36},
publisher = {Elsevier B.V},
number = {2},
year = {2020},
title = {Model-based pre-election polling for national and sub-national outcomes in the US and UK},
copyright = {2019 International Institute of Forecasters},
language = {eng},
address = {AMSTERDAM},
author = {Lauderdale, Benjamin E and Bailey, Delia and Blumenau, Jack and Rivers, Douglas},
keywords = {Business & Economics ; Economics ; Election forecasting ; Elections ; Management ; Multilevel regression and stratification ; Polling ; Presidents ; Social Sciences ; UK politics ; US politics},
}

@article{LeiRayleigh2017T2EA,
issn = {2330-443X},
abstract = {We present an increasingly stringent set of replications, a multilevel regression and poststratification analysis of polls from the 2008 U.S. presidential election campaign, focusing on a set of plots showing the estimated Republican vote share for whites and for all voters, as a function of income level in each of the states.
 We start with a nearly exact duplication that uses the posted code and changes only the model-fitting algorithm; we then replicate using already-analyzed data from 2004; and finally we set up preregistered replications using two surveys from 2008 that we had not previously looked at. We have already learned from our preliminary, nonpreregistered replication, which has revealed a potential problem with the earlier published analysis; it appears that our model may not sufficiently account for nonsampling error, and that some of the patterns presented in that earlier article may simply reflect noise.
 In addition to the substantive interest in validating earlier findings about demographics, geography, and voting, the present project serves as a demonstration of preregistration in a setting where the subject matter is historical (and thus the replication data exist before the preregistration plan is written) and where the analysis is exploratory (and thus a replication cannot be simply deemed successful or unsuccessful based on the statistical significance of some particular comparison).
 Our replication analysis produced graphs that showed the same general pattern of income and voting as we had found in our earlier published work, but with some differences in particular states that we cannot easily explain and which seem too large to be explained by sampling variation. This process thus demonstrates how replication can raise concerns about an earlier published result.},
journal = {Statistics and Public Policy},
pages = {1--8},
volume = {4},
publisher = {Taylor & Francis},
number = {1},
year = {2017},
title = {The 2008 Election: A Preregistered Replication Analysis},
copyright = {2017 The Author(s). Published with license by American Statistical Association © Rayleigh Lei, Andrew Gelman, and Yair Chitza 2017},
language = {eng},
address = {Macclesfield},
author = {Lei, Rayleigh and Gelman, Andrew and Ghitza, Yair},
keywords = {Algorithms ; Bayesian analysis ; Bayesian methods ; Elections ; Graphs ; Other ; Polls & surveys ; Presidential elections ; Process improvement ; Public opinion surveys ; Sampling ; Statistical significance ; Voter behavior ; Voters ; Voting},
}

@article{ParkDavidK2004BMEw,
issn = {1047-1987},
abstract = {We fit a multilevel logistic regression model for the mean of a binary response variable conditional on poststratification cells. This approach combines the modeling approach often used in small-area estimation with the population information used in poststratification (see Gelman and Little 1997, Survey Methodology 23:127–135). To validate the method, we apply it to U.S. preelection polls for 1988 and 1992, poststratified by state, region, and the usual demographic variables. We evaluate the model by comparing it to state-level election outcomes. The multilevel model outperforms more commonly used models in political science. We envision the most important usage of this method to be not forecasting elections but estimating public opinion on a variety of issues at the state level.},
journal = {Political analysis},
pages = {375--385},
volume = {12},
publisher = {Cambridge University Press},
number = {4},
year = {2004},
title = {Bayesian Multilevel Estimation with Poststratification: State-Level Estimates from National Polls},
copyright = {Copyright © Society for Political Methodology 2004},
language = {eng},
address = {New York, US},
author = {Park, David K and Gelman, Andrew and Bafumi, Joseph},
keywords = {Demography ; Ethnicity ; Modeling ; Multilevel models ; Polls ; Population estimates ; Public opinion ; State elections ; Voter registration ; Voting},
}

@article{WangWei2015Fewn,
issn = {0169-2070},
abstract = {Byline: Wei Wang, David Rothschild, Sharad Goel, Andrew Gelman Election forecasts have traditionally been based on representative polls, in which randomly sampled individuals are asked who they intend to vote for. While representative polling has historically proven to be quite effective, it comes at considerable costs of time and money. Moreover, as response rates have declined over the past several decades, the statistical benefits of representative sampling have diminished. In this paper, we show that, with proper statistical adjustment, non-representative polls can be used to generate accurate election forecasts, and that this can often be achieved faster and at a lesser expense than traditional survey methods. We demonstrate this approach by creating forecasts from a novel and highly non-representative survey dataset: a series of daily voter intention polls for the 2012 presidential election conducted on the Xbox gaming platform. After adjusting the Xbox responses via multilevel regression and poststratification, we obtain estimates which are in line with the forecasts from leading poll analysts, which were based on aggregating hundreds of traditional polls conducted during the election cycle. We conclude by arguing that non-representative polling shows promise not only for election forecasting, but also for measuring public opinion on a broad range of social, economic and cultural issues.},
journal = {International journal of forecasting},
pages = {980--991},
volume = {31},
publisher = {Elsevier B.V},
number = {3},
year = {2015},
title = {Forecasting elections with non-representative polls},
copyright = {COPYRIGHT 2015 Elsevier B.V.},
language = {eng},
address = {Amsterdam},
author = {Wang, Wei and Rothschild, David and Goel, Sharad and Gelman, Andrew},
keywords = {Elections ; Forecasting techniques ; Presidential elections ; Public opinion surveys ; Regression analysis ; Studies},
}

@misc{cces_data,
author = {Ansolabehere, Stephen and Schaffner, Brian F.},
publisher = {Harvard Dataverse},
title = {{CCES Common Content, 2016}},
UNF = {UNF:6:WhtR8dNtMzReHC295hA4cg==},
year = {2017},
version = {V4},
doi = {10.7910/DVN/GDF6Z0},
url = {https://doi.org/10.7910/DVN/GDF6Z0}
}

@misc{acs_data,
author = {{U.S. Census Bureau}},
publisher = {{{U.S. Census Bureau}}},
title = {{The American Community Survey Public Use Microdata Sample, 2015-2017}},
year = {2021},
url = {https://www.census.gov/programs-surveys/acs/microdata/}
}

@phdthesis{kuriwaki,
author = {Shiro Kuriwaki},
title = {The Swing Voter Paradox: Electoral Politics in a Nationalized Era}, publisher = {Harvard University}, address = {Cambridge MA},
year = {2021}
}

@Manual{ccesmrpprep,
    title = {ccesMRPprep: Functions and Data to Prepare CCES data for MRP},
    author = {Shiro Kuriwaki},
    year = {2021},
    note = {R package version 0.1.8.900},
    url = {https://www.github.com/kuriwaki/ccesMRPprep},
  }

@misc{acs_data_about,
author = {{U.S. Census Bureau}},
publisher = {{{U.S. Census Bureau}}},
title = {{About the American Community Survey}},
year = {2021},
url = {https://www.census.gov/programs-surveys/acs/about.html}
}

@article{GaoYuxiang2021IMRa,
issn = {1936-0975},
journal = {Bayesian analysis},
volume = {1},
number = {1},
year = {2021},
title = {Improving Multilevel Regression and Poststratification with Structured Priors},
language = {eng},
author = {Gao, Yuxiang and Kennedy, Lauren and Simpson, Daniel and Gelman, Andrew},
}

@misc{acs_coverage_rate,
author = {{U.S. Census Bureau}},
publisher = {{{U.S. Census Bureau}}},
title = {{American Community Survey: Sample Size and Data Quality}},
year = {2021},
url = {https://www.census.gov/acs/www/methodology/sample-size-and-data-quality/}
}

@misc{pums_metadata,
author = {{U.S. Census Bureau}},
publisher = {{{U.S. Census Bureau}}},
title = {{American Community Survey 2015: ACS 1-Year PUMS Files}},
year = {2016},
url = {https://www2.census.gov/programs-surveys/acs/tech_docs/pums/ACS2015_PUMS_README.pdf}
}

@Manual{mrpkit,
title = {mrpkit: Multilevel Regression with Post-Stratification},
author = {{Kennedy, Gabry, Amaliah, Alexander}},
note = {R package version 0.1.0},
year = {2021}
}

@Article{brms,
    title = {Advanced {Bayesian} Multilevel Modeling with the {R} Package {brms}},
    author = {Paul-Christian Bürkner},
    journal = {The R Journal},
    year = {2018},
    volume = {10},
    number = {1},
    pages = {395--411},
    doi = {10.32614/RJ-2018-017},
    encoding = {UTF-8},
  }
  
@Manual{cmdstanr,
    title = {cmdstanr: R Interface to 'CmdStan'},
    author = {Jonah Gabry and Rok Češnovar},
    year = {2021},
    note = {https://mc-stan.org/cmdstanr, https://discourse.mc-stan.org},
  }

@misc{mrp-book, 
    title={Multilevel Regression and Poststratification Case Studies}, 
    url={https://bookdown.org/jl5522/MRP-case-studies/}, 
    author={Juan Lopez-Martin and Justin H. Phillips and Andrew Gelman}, 
    year={2021}, 
}

@book{ClevelandWilliamS,
publisher = {Wadsworth Advanced Books and Software},
isbn = {0534037305},
year = {1985},
title = {The elements of graphing data},
language = {eng},
address = {Monterey, Calif.},
author = {Cleveland, William S.},
keywords = {Graphic methods},
lccn = {85010603},
}

@book{1983Gmfd,
series = {The Wadsworth statistics/probability series},
publisher = {Wadsworth International Group ; Duxbury Press},
author = {John M. Chambers},
isbn = {053498052X},
year = {1983},
title = {Graphical methods for data analysis},
language = {eng},
address = {Belmont, Calif. : Boston},
keywords = {Statistics -- Graphic methods; Computer graphics},
}

@article{WickhamHadley2015VsmR,
issn = {1932-1864},
abstract = {Visualization can help in model building, diagnosis, and in developing an understanding about how a model summarizes data. This paper proposes three strategies for visualizing statistical models: (i) display the model in the data space, (ii) look at all members of a collection, and (iii) explore the process of model fitting, not just the end result. Each strategy is accompanied by examples, including manova, classification algorithms, hierarchical clustering, ensembles of linear models, projection pursuit, self‐organizing maps, and neural networks.},
journal = {Statistical analysis and data mining},
pages = {203--225},
volume = {8},
publisher = {Wiley Subscription Services, Inc., A Wiley Company},
number = {4},
year = {2015},
title = {Visualizing statistical models: Removing the blindfold},
copyright = {2015 Wiley Periodicals, Inc.},
language = {eng},
address = {Hoboken},
author = {Wickham, Hadley and Cook, Dianne and Hofmann, Heike},
keywords = {Algorithms ; classification ; Cluster analysis ; Clustering ; data mining ; exploratory data analysis ; high-dimensional data ; model visualization ; Neural networks ; Statistical models},
}

@incollection{mekelagelman,
author = {Susanna Makela and Yajuan Si and Andrew Gelman},
title = {Graphical Visualization of Polling Results},
editor = {Lonna Atkeson and Michael Alvarez},
booktitle = {The Oxford Handbook on Polling and Polling Methods},
publisher = {Oxford University Press}, address = {Oxford UK},
year = {2017},
doi = {10.1093/oxfordhb/9780190213299.013.12}, 
}

@incollection{saundra,
author = {Saundra K. Schneider and William G. Jacoby},
title = {Graphical Displays for Public Opinion Research},
editor = {Lonna Atkeson and Michael Alvarez},
booktitle = {The Oxford Handbook on Polling and Polling Methods},
publisher = {Oxford University Press}, address = {Oxford UK},
year = {2017},
doi = {10.1093/oxfordhb/9780190213299.013.10}, 
}

@inbook{statgraph,
author = {Wickham, Hadley},
publisher = {American Cancer Society},
isbn = {9780470057339},
title = {Statistical Graphics},
booktitle = {Encyclopedia of Environmetrics},
chapter = {},
pages = {},
doi = {https://doi.org/10.1002/9780470057339.vnn164},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9780470057339.vnn164},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9780470057339.vnn164},
year = {2013},
keywords = {visualisation, cognitive psychology, scatterplot, histogram, perception, grammar of graphics, maps},
abstract = {Abstract Statistical graphics (let alone visualisation) is a very broad field. This article is my personal take on it, focussing on the works that are most useful for creating insightful graphics. Visualisations work because they display data in a way that is easy for the brain to parse and interpret: this means we need to know a little bit about cognitive psychology, particularly the perception of continuous values, colour and differences. It's also helpful to be aware of what's already been done, so I also summarise the origins the most common statistical graphics, plots of statistical summaries, graphics for high-dimensional data, display spatial data, and the grammar of graphics.}
}

@article{EunKimSung2018Epoi,
issn = {0964-4016},
abstract = {Partisan polarization of public opinion is a major trend in American environmental politics. While the national pattern is widely recognized, scholars know much less about the polarization of public opinion over time at the state level. This lack of knowledge is unfortunate because geographic variation in the polarization of opinion is essential for explaining the origins of partisan polarization and evaluating its consequences for policy. To fill the gap, the multilevel regression and poststratification technique is applied to provide credible estimates of state-level environmental public opinion for both Democrats and Republicans, 1973-2012. It appears that the growing partisan gap reflects increased pro-environmental opinion among Democrats across many states, whereas Republican state-level public opinion is converging toward a much lower baseline. Cross-state variation among both parties has decreased over time, contributing to greater partisan polarization in the aggregate. Changes in the sorting of voters in and out of political parties cannot explain these patterns of polarization.},
journal = {Environmental politics},
pages = {89--114},
volume = {27},
publisher = {Routledge},
number = {1},
year = {2018},
title = {Environmental public opinion in U.S. states, 1973-2012},
copyright = {2017 Informa UK Limited, trading as Taylor & Francis Group 2017},
language = {eng},
author = {Eun Kim, Sung and Urpelainen, Johannes},
keywords = {American politics ; environmental politics ; partisan polarization ; public opinion},
}

@article{HullmanJessica2019IPoE,
issn = {1077-2626},
abstract = {Understanding and accounting for uncertainty is critical to effectively reasoning about visualized data. However, evaluating the impact of an uncertainty visualization is complex due to the difficulties that people have interpreting uncertainty and the challenge of defining correct behavior with uncertainty information. Currently, evaluators of uncertainty visualization must rely on general purpose visualization evaluation frameworks which can be ill-equipped to provide guidance with the unique difficulties of assessing judgments under uncertainty. To help evaluators navigate these complexities, we present a taxonomy for characterizing decisions made in designing an evaluation of an uncertainty visualization. Our taxonomy differentiates six levels of decisions that comprise an uncertainty visualization evaluation: the behavioral targets of the study, expected effects from an uncertainty visualization, evaluation goals, measures, elicitation techniques, and analysis approaches. Applying our taxonomy to 86 user studies of uncertainty visualizations, we find that existing evaluation practice, particularly in visualization research, focuses on Performance and Satisfaction-based measures that assume more predictable and statistically-driven judgment behavior than is suggested by research on human judgment and decision making. We reflect on common themes in evaluation practice concerning the interpretation and semantics of uncertainty, the use of confidence reporting, and a bias toward evaluating performance as accuracy rather than decision quality. We conclude with a concrete set of recommendations for evaluators designed to reduce the mismatch between the conceptualization of uncertainty in visualization versus other fields.},
journal = {IEEE transactions on visualization and computer graphics},
pages = {903--913},
volume = {25},
publisher = {IEEE},
number = {1},
year = {2019},
title = {In Pursuit of Error: A Survey of Uncertainty Visualization Evaluation},
language = {eng},
address = {United States},
author = {Hullman, Jessica and Xiaoli Qiao and Correll, Michael and Kale, Alex and Kay, Matthew},
keywords = {Data visualization ; Decision making ; Measurement uncertainty ; probability distribution ; subjective confidence ; Task analysis ; Taxonomy ; Uncertainty ; Uncertainty visualization ; user study ; Visualization},
}

@article{EnnsPeterK2013POit,
issn = {1532-4400},
abstract = {In this article, we create, validate, and analyze new dynamic measures of state partisanship, state policy mood, and state political ideology. The measures of partisanship and policy mood begin in 1956 and the measure of ideology begins in 1976. Our approach uses the advantages of two leading techniques for measuring state public opinion—multilevel regression and poststratification (MRP) and survey aggregation. The resulting estimates are based on nearly 500 different surveys with a total of more than 740,000 respondents. After validating our measures, we show that during the last half century, policy preferences in the states have shifted in important and sometimes surprising ways. For example, we find that differences in political attitudes across time can be as important as differences across states.},
journal = {State politics and policy quarterly},
pages = {349--372},
volume = {13},
publisher = {SAGE Publications},
number = {3},
year = {2013},
title = {Public Opinion in the U.S. States: 1956 to 2010},
copyright = {Copyright © 2013 State Politics and Policy Section of the American Political Science Association},
language = {eng},
address = {Los Angeles, CA},
author = {Enns, Peter K and Koch, Julianna},
}

@article{tukey,
author = {John W. Tukey},
title = {Graphic Comparisons of Several Linked Aspects: Alternatives and Suggested Principles},
journal = {Journal of Computational and Graphical Statistics},
volume = {2},
number = {1},
pages = {1-33},
year  = {1993},
publisher = {Taylor & Francis},
doi = {10.1080/10618600.1993.10474595},
URL = {https://www.tandfonline.com/doi/abs/10.1080/10618600.1993.10474595},
eprint = {https://www.tandfonline.com/doi/pdf/10.1080/10618600.1993.10474595},
}

@article{gelmanunwin,
issn = {1061-8600},
abstract = {The importance of graphical displays in statistical practice has been recognized sporadically in the statistical literature over the past century, with wider awareness following Tukey's Exploratory Data Analysis and Tufte's books in the succeeding decades. But statistical graphics still occupy an awkward in-between position: within statistics, exploratory and graphical methods represent a minor subfield and are not well integrated with larger themes of modeling and inference. Outside of statistics, infographics (also called information visualization or Infovis) are huge, but their purveyors and enthusiasts appear largely to be uninterested in statistical principles.
We present here a set of goals for graphical displays discussed primarily from the statistical point of view and discuss some inherent contradictions in these goals that may be impeding communication between the fields of statistics and Infovis. One of our constructive suggestions, to Infovis practitioners and statisticians alike, is to try not to cram into a single graph what can be better displayed in two or more. We recognize that we offer only one perspective and intend this article to be a starting point for a wide-ranging discussion among graphic designers, statisticians, and users of statistical methods. The purpose of this article is not to criticize but to explore the different goals that lead researchers in different fields to value different aspects of data visualization.},
journal = {Journal of computational and graphical statistics},
pages = {2--28},
volume = {22},
publisher = {Taylor & Francis Group},
number = {1},
year = {2013},
title = {Infovis and Statistical Graphics: Different Goals, Different Looks},
copyright = {Copyright Taylor & Francis Group, LLC 2013},
language = {eng},
address = {Alexandria},
author = {Gelman, Andrew and Unwin, Antony},
keywords = {Computer graphics ; Graphic designers ; Graphics ; Infovis ; International Year of Statistics Featured Discussion: Info Vis ; Statistical communication ; Statistical methods ; Statistics ; Studies ; Visualization},
}

@article{WarshawChristopher2012HSWM,
issn = {0022-3816},
abstract = {Due to insufficient sample sizes in national surveys, strikingly little is known about public opinion at the level of Congressional and state legislative districts in the United States. As a result, there has been virtually no study of whether legislators accurately represent the will of their constituents on individual issues. This article solves this problem by developing a multilevel regression and poststratification (MRP) model that combines survey and census data to estimate public opinion at the district level. We show that MRP estimates are excellent predictors of public opinion and referenda results for both congressional and state senate districts. Moreover, they have less error, higher correlations, and lower variance than either disaggregated survey estimates or presidential vote shares. The MRP approach provides American and Comparative Politics scholars with a valuable new tool to measure issue-specific public opinion at low levels of geographic aggregation.},
journal = {The Journal of politics},
pages = {203--219},
volume = {74},
publisher = {Cambridge University Press},
number = {1},
year = {2012},
title = {How Should We Measure District-Level Public Opinion on Individual Issues?},
copyright = {Copyright © Southern Political Science Association 2012},
language = {eng},
address = {New York, USA},
author = {Warshaw, Christopher and Rodden, Jonathan},
keywords = {Congressional districts ; Demography ; Electoral districts ; Modeling ; Opinion polls ; Presidential elections ; Public opinion ; Same sex marriage ; Sample size ; Voting},
}

@article{hanretty,
author = {Chris Hanretty},
title ={An Introduction to Multilevel Regression and Post-Stratification for Estimating Constituency Opinion},
journal = {Political Studies Review},
volume = {18},
number = {4},
pages = {630-645},
year = {2020},
doi = {10.1177/1478929919864773},
URL = {https://doi.org/10.1177/1478929919864773},
eprint = {https://doi.org/10.1177/1478929919864773},
abstract = { This article provides an overview of multilevel regression and post-stratification. It reviews the stages in estimating opinion for small areas, identifies circumstances in which multilevel regression and post-stratification can go wrong, or go right, and provides a worked example for the UK using publicly available data sources and a previously published post-stratification frame.},
}

@article{MengXiao-Li2018Spap,
issn = {1932-6157},
journal = {The annals of applied statistics},
volume = {12},
number = {2},
year = {2018},
title = {Statistical paradises and paradoxes in big data (I): Law of large populations, big data paradox, and the 2016 US presidential election},
language = {eng},
author = {Meng, Xiao-Li},
}

@Manual{R,
    title = {R: A Language and Environment for Statistical Computing},
    author = {{R Core Team}},
    organization = {R Foundation for Statistical Computing},
    address = {Vienna, Austria},
    year = {2020},
    url = {https://www.R-project.org/},
  }


